{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bu1DQZUW7ui7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n",
      "'mv' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'chmod' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ds-ZzSSK8NuX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/towfiqtomal/tongue-diabetes\n",
      "License(s): Apache 2.0\n",
      "Downloading tongue-diabetes.zip to C:\\Users\\Siku\\Downloads\\mylearning\\tongue\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/81.1M [00:00<?, ?B/s]\n",
      "  1%|1         | 1.00M/81.1M [00:01<01:35, 883kB/s]\n",
      "  2%|2         | 2.00M/81.1M [00:01<00:53, 1.55MB/s]\n",
      "  4%|3         | 3.00M/81.1M [00:04<02:32, 537kB/s] \n",
      "  5%|4         | 4.00M/81.1M [00:05<01:43, 780kB/s]\n",
      "  6%|6         | 5.00M/81.1M [00:05<01:18, 1.01MB/s]\n",
      "  7%|7         | 6.00M/81.1M [00:06<01:03, 1.24MB/s]\n",
      "  9%|8         | 7.00M/81.1M [00:06<00:52, 1.47MB/s]\n",
      " 10%|9         | 8.00M/81.1M [00:07<00:42, 1.79MB/s]\n",
      " 11%|#1        | 9.00M/81.1M [00:07<00:36, 2.06MB/s]\n",
      " 12%|#2        | 10.0M/81.1M [00:07<00:30, 2.41MB/s]\n",
      " 14%|#3        | 11.0M/81.1M [00:07<00:27, 2.71MB/s]\n",
      " 15%|#4        | 12.0M/81.1M [00:08<00:23, 3.10MB/s]\n",
      " 16%|#6        | 13.0M/81.1M [00:08<00:20, 3.43MB/s]\n",
      " 17%|#7        | 14.0M/81.1M [00:08<00:19, 3.69MB/s]\n",
      " 18%|#8        | 15.0M/81.1M [00:08<00:17, 4.02MB/s]\n",
      " 20%|#9        | 16.0M/81.1M [00:09<00:20, 3.33MB/s]\n",
      " 21%|##        | 17.0M/81.1M [00:09<00:23, 2.87MB/s]\n",
      " 22%|##2       | 18.0M/81.1M [00:10<00:21, 3.12MB/s]\n",
      " 23%|##3       | 19.0M/81.1M [00:10<00:20, 3.21MB/s]\n",
      " 25%|##4       | 20.0M/81.1M [00:10<00:19, 3.37MB/s]\n",
      " 26%|##5       | 21.0M/81.1M [00:11<00:19, 3.27MB/s]\n",
      " 27%|##7       | 22.0M/81.1M [00:11<00:18, 3.28MB/s]\n",
      " 28%|##8       | 23.0M/81.1M [00:11<00:21, 2.82MB/s]\n",
      " 30%|##9       | 24.0M/81.1M [00:13<00:47, 1.27MB/s]\n",
      " 31%|###       | 25.0M/81.1M [00:14<00:39, 1.47MB/s]\n",
      " 32%|###2      | 26.0M/81.1M [00:14<00:36, 1.58MB/s]\n",
      " 33%|###3      | 27.0M/81.1M [00:14<00:29, 1.92MB/s]\n",
      " 35%|###4      | 28.0M/81.1M [00:15<00:25, 2.18MB/s]\n",
      " 36%|###5      | 29.0M/81.1M [00:15<00:22, 2.42MB/s]\n",
      " 37%|###6      | 30.0M/81.1M [00:16<00:22, 2.33MB/s]\n",
      " 38%|###8      | 31.0M/81.1M [00:16<00:20, 2.57MB/s]\n",
      " 39%|###9      | 32.0M/81.1M [00:16<00:18, 2.82MB/s]\n",
      " 41%|####      | 33.0M/81.1M [00:17<00:18, 2.66MB/s]\n",
      " 42%|####1     | 34.0M/81.1M [00:17<00:16, 2.94MB/s]\n",
      " 43%|####3     | 35.0M/81.1M [00:19<00:41, 1.15MB/s]\n",
      " 44%|####4     | 36.0M/81.1M [00:19<00:33, 1.43MB/s]\n",
      " 46%|####5     | 37.0M/81.1M [00:20<00:27, 1.66MB/s]\n",
      " 47%|####6     | 38.0M/81.1M [00:20<00:25, 1.74MB/s]\n",
      " 48%|####8     | 39.0M/81.1M [00:21<00:20, 2.11MB/s]\n",
      " 49%|####9     | 40.0M/81.1M [00:21<00:19, 2.26MB/s]\n",
      " 51%|#####     | 41.0M/81.1M [00:21<00:16, 2.59MB/s]\n",
      " 52%|#####1    | 42.0M/81.1M [00:22<00:14, 2.82MB/s]\n",
      " 53%|#####3    | 43.0M/81.1M [00:22<00:14, 2.71MB/s]\n",
      " 54%|#####4    | 44.0M/81.1M [00:22<00:13, 2.97MB/s]\n",
      " 55%|#####5    | 45.0M/81.1M [00:23<00:11, 3.24MB/s]\n",
      " 57%|#####6    | 46.0M/81.1M [00:23<00:10, 3.40MB/s]\n",
      " 58%|#####7    | 47.0M/81.1M [00:23<00:10, 3.51MB/s]\n",
      " 59%|#####9    | 48.0M/81.1M [00:23<00:09, 3.67MB/s]\n",
      " 60%|######    | 49.0M/81.1M [00:24<00:09, 3.74MB/s]\n",
      " 62%|######1   | 50.0M/81.1M [00:24<00:09, 3.49MB/s]\n",
      " 63%|######2   | 51.0M/81.1M [00:24<00:10, 2.95MB/s]\n",
      " 64%|######4   | 52.0M/81.1M [00:25<00:10, 2.80MB/s]\n",
      " 65%|######5   | 53.0M/81.1M [00:25<00:11, 2.64MB/s]\n",
      " 67%|######6   | 54.0M/81.1M [00:26<00:12, 2.21MB/s]\n",
      " 68%|######7   | 55.0M/81.1M [00:26<00:10, 2.50MB/s]\n",
      " 69%|######9   | 56.0M/81.1M [00:27<00:09, 2.69MB/s]\n",
      " 70%|#######   | 57.0M/81.1M [00:28<00:16, 1.49MB/s]\n",
      " 72%|#######1  | 58.0M/81.1M [00:28<00:14, 1.67MB/s]\n",
      " 73%|#######2  | 59.0M/81.1M [00:29<00:11, 1.97MB/s]\n",
      " 74%|#######3  | 60.0M/81.1M [00:29<00:09, 2.22MB/s]\n",
      " 75%|#######5  | 61.0M/81.1M [00:29<00:08, 2.39MB/s]\n",
      " 76%|#######6  | 62.0M/81.1M [00:30<00:07, 2.67MB/s]\n",
      " 78%|#######7  | 63.0M/81.1M [00:30<00:06, 2.88MB/s]\n",
      " 79%|#######8  | 64.0M/81.1M [00:30<00:05, 3.03MB/s]\n",
      " 80%|########  | 65.0M/81.1M [00:31<00:05, 3.27MB/s]\n",
      " 81%|########1 | 66.0M/81.1M [00:31<00:04, 3.53MB/s]\n",
      " 83%|########2 | 67.0M/81.1M [00:31<00:03, 3.71MB/s]\n",
      " 84%|########3 | 68.0M/81.1M [00:31<00:03, 3.83MB/s]\n",
      " 85%|########5 | 69.0M/81.1M [00:32<00:04, 2.86MB/s]\n",
      " 86%|########6 | 70.0M/81.1M [00:33<00:05, 2.29MB/s]\n",
      " 88%|########7 | 71.0M/81.1M [00:33<00:04, 2.49MB/s]\n",
      " 89%|########8 | 72.0M/81.1M [00:33<00:03, 2.53MB/s]\n",
      " 90%|######### | 73.0M/81.1M [00:34<00:03, 2.39MB/s]\n",
      " 91%|#########1| 74.0M/81.1M [00:34<00:02, 2.65MB/s]\n",
      " 92%|#########2| 75.0M/81.1M [00:34<00:02, 2.96MB/s]\n",
      " 94%|#########3| 76.0M/81.1M [00:35<00:01, 3.27MB/s]\n",
      " 95%|#########4| 77.0M/81.1M [00:35<00:01, 3.57MB/s]\n",
      " 96%|#########6| 78.0M/81.1M [00:35<00:00, 3.73MB/s]\n",
      " 97%|#########7| 79.0M/81.1M [00:35<00:00, 3.82MB/s]\n",
      " 99%|#########8| 80.0M/81.1M [00:36<00:00, 3.86MB/s]\n",
      "100%|#########9| 81.0M/81.1M [00:36<00:00, 3.77MB/s]\n",
      "100%|##########| 81.1M/81.1M [00:36<00:00, 2.34MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d towfiqtomal/tongue-diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wuyBtvgO8hb4"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1406514273.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    unzip /content/tongue-diabetes.zip -d /content/\u001b[0m\n\u001b[1;37m                                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "unzip /content/tongue-diabetes.zip -d /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aeuCRfEJ-mTD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import imghdr\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tensorflow.keras import layers, models, regularizers, optimizers\n",
    "from tensorflow.keras.applications import VGG16, ResNet50V2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard, CSVLogger\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4UeHKSm-0Wr"
   },
   "outputs": [],
   "source": [
    "os.makedirs('test_dir', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RTZd2tQ-9fg"
   },
   "outputs": [],
   "source": [
    "# Define your project name\n",
    "project_name = 'Tongue Detection'\n",
    "\n",
    "# List your models\n",
    "model_names = [\n",
    "    'Custom_CNN_From_Scratch',\n",
    "    'Custom_CNN_With_Augmentation',\n",
    "    'VGG16_Transfer_Learning',\n",
    "    'ResNet50_Transfer_Learning'\n",
    "]\n",
    "\n",
    "# Base directory (in this case, your Google Colab workspace)\n",
    "base_dir = '/content/'\n",
    "\n",
    "# Create the project directory\n",
    "project_dir = os.path.join(base_dir, project_name)\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "\n",
    "# Create a subdirectory for each model\n",
    "for each_model in model_names:\n",
    "    model_dir = os.path.join(project_dir, each_model)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Example subdirectories for model-related files\n",
    "    # os.makedirs(os.path.join(model_dir, 'checkpoints'), exist_ok=True)\n",
    "    # os.makedirs(os.path.join(model_dir, 'logs'), exist_ok=True)\n",
    "    # os.makedirs(os.path.join(model_dir, 'saved_models'), exist_ok=True)\n",
    "\n",
    "print(f'Project directory structure created at: {project_dir}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFstNKgt-6vN"
   },
   "outputs": [],
   "source": [
    "# Define the list of acceptable image extensions\n",
    "image_exts = ['jpeg', 'jpg', 'png']\n",
    "\n",
    "# Path to the directory containing image classes and possibly other nested subdirectories\n",
    "data_dir = '/content/output_train'\n",
    "\n",
    "# Walk through all directories and files in the dataset\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        # Construct the path to the current file\n",
    "        file_path = os.path.join(root, file)\n",
    "\n",
    "        try:\n",
    "            # Check the file type of the current file\n",
    "            file_type = imghdr.what(file_path)\n",
    "\n",
    "            # If the file extension is not in the allowed list, remove it\n",
    "            if file_type not in image_exts:\n",
    "                print(f'Image not in ext list {file_path}')\n",
    "                os.remove(file_path)\n",
    "            else:\n",
    "                # Proceed to process the image if needed, for example, reading it with OpenCV\n",
    "                img = cv2.imread(file_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Print out the issue and the path of the problematic file\n",
    "            print(f'Issue with file {file_path}. Error: {e}')\n",
    "            # Optionally, remove files that cause exceptions\n",
    "            os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_bO4QXs_F2o"
   },
   "outputs": [],
   "source": [
    "# Define a function to count the number of files (assumed to be images for this context) for each subdirectory in a given directory.\n",
    "# The function returns a DataFrame with these counts, indexed by a specified set name (e.g., 'train' or 'test').\n",
    "def count_files_in_subdirs(directory, set_name):\n",
    "    # Initialize an empty dictionary to hold the count of files for each subdirectory.\n",
    "    counts = {}\n",
    "\n",
    "    # Iterate over each item in the given directory.\n",
    "    for item in os.listdir(directory):\n",
    "        # Construct the full path to the item.\n",
    "        item_path = os.path.join(directory, item)\n",
    "\n",
    "        # Check if the item is a directory.\n",
    "        if os.path.isdir(item_path):\n",
    "            # Count the number of files in the subdirectory and add it to the dictionary.\n",
    "            counts[item] = len(os.listdir(item_path))\n",
    "\n",
    "    # Convert the counts dictionary to a DataFrame for easy viewing and analysis.\n",
    "    # The index of the DataFrame is set to the provided set name.\n",
    "    df = pd.DataFrame(counts, index=[set_name])\n",
    "    return df\n",
    "\n",
    "# Paths to the training and testing directories.\n",
    "train_dir = '/content/output_train'\n",
    "test_dir = '/content/output_valid'\n",
    "\n",
    "# Count the files in the subdirectories of the training directory and print the result.\n",
    "train_count = count_files_in_subdirs(train_dir, 'train')\n",
    "print(train_count)\n",
    "\n",
    "# Count the files in the subdirectories of the testing directory and print the result.\n",
    "test_count = count_files_in_subdirs(test_dir, 'test')\n",
    "print(test_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUYSgT03_bFj"
   },
   "outputs": [],
   "source": [
    "train_count.transpose().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ch4oY8iU_ecZ"
   },
   "outputs": [],
   "source": [
    "test_count.transpose().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-Wbmf4s_kIN"
   },
   "outputs": [],
   "source": [
    "diabetes = os.listdir(train_dir)\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "for i, diabete in enumerate(diabetes, 1):\n",
    "    folder = os.path.join(train_dir, diabete)\n",
    "    img_path = os.path.join(folder, os.listdir(folder)[42])\n",
    "    img = plt.imread(img_path)\n",
    "    plt.subplot(3, 4, i)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(diabete)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FKkQyykc_oSD"
   },
   "outputs": [],
   "source": [
    "def plot_images_from_directory(directory_path, class_name, num_images=9):\n",
    "    # Retrieve list of all file names in the directory\n",
    "    image_filenames = os.listdir(directory_path)\n",
    "\n",
    "\n",
    "    # If there are fewer images than requested, we'll just show them all\n",
    "    if len(image_filenames) < num_images:\n",
    "        print(f\"Only found {len(image_filenames)} images in {directory_path}, displaying them all.\")\n",
    "        num_images = len(image_filenames)\n",
    "\n",
    "    # Randomly select 'num_images' number of file names\n",
    "    selected_images = random.sample(image_filenames, num_images)\n",
    "\n",
    "    # Plotting the images\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(5, 5))  # Adjust the size as needed\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i, image_file in enumerate(selected_images):\n",
    "        image_path = os.path.join(directory_path, image_file)\n",
    "        # image = Image.open(image_path)\n",
    "        image = load_img(image_path)\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].set_title(f\"Image: {class_name}\")\n",
    "        axes[i].axis('off')  # Hide the axis\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rv5f1tmE_8zl"
   },
   "outputs": [],
   "source": [
    "# Placeholder for the directory path\n",
    "angry_directory_path = '/content/output_train/diabetes'  # Replace with your directory path\n",
    "plot_images_from_directory(angry_directory_path, class_name = 'diabetes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rs-iAjnDAIWJ"
   },
   "outputs": [],
   "source": [
    "# Placeholder for the directory path\n",
    "angry_directory_path = '/content/output_train/non_diabetes'  # Replace with your directory path\n",
    "plot_images_from_directory(angry_directory_path, class_name = 'non-diabetes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-q5RISPAaxz"
   },
   "outputs": [],
   "source": [
    "image = '/content/output_train/diabetes/Screenshot_3_jpg.rf.b223093049b465eb97a6439b50c05b44.jpg'\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(image) # Default load in color format.\n",
    "\n",
    "# If the image is loaded successfully, print its pixel values\n",
    "if img is not None:\n",
    "    # print(img)\n",
    "    print(\"Shape:\", img.shape)\n",
    "else:\n",
    "    print(\"The image could not be loaded. Please check the path and file permissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-hnMXZXAe14"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image_path = '/content/output_train/diabetes/Screenshot_3_jpg.rf.b223093049b465eb97a6439b50c05b44.jpg'\n",
    "\n",
    "# Load the image in grayscale\n",
    "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# If the image is loaded successfully, print its pixel values\n",
    "if img is not None:\n",
    "    # print(img)\n",
    "    print(\"Shape:\", img.shape)  # This should now print (48, 48)\n",
    "else:\n",
    "    print(\"The image could not be loaded. Please check the path and file permissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImKS_5x7AubV"
   },
   "outputs": [],
   "source": [
    "# Define paths to the train and validation directories\n",
    "train_data_dir = '/content/output_train'\n",
    "test_data_dir = '/content/output_valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DuJhrngxA9eE"
   },
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "img_width, img_height = 640, 640  # Size of images\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "num_classes = 2  # Update this based on the number of your classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZlrI3qVBAdO"
   },
   "outputs": [],
   "source": [
    "# Rescale the pixel values (0-255) to the [0, 1] interval\n",
    "data_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                    validation_split=0.2)\n",
    "\n",
    "# Automatically retrieve images and their classes for train and validation sets\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    subset='validation')\n",
    "\n",
    "test_generator = data_generator.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',)\n",
    "    # subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VngabtfoBhUo"
   },
   "outputs": [],
   "source": [
    "# Accessing class labels for the training data\n",
    "train_class_labels = train_generator.class_indices\n",
    "print(\"Training class labels:\", train_class_labels)\n",
    "\n",
    "# Accessing class labels for the validation data\n",
    "validation_class_labels = validation_generator.class_indices\n",
    "print(\"Validation class labels:\", validation_class_labels)\n",
    "\n",
    "# Accessing class labels for the validation data\n",
    "test_class_labels = test_generator.class_indices\n",
    "print(\"Validation class labels:\", test_class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gH8gcCEdIRmg"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "# config = tf.compat.v1.ConfigProto(gpu_options=gpu_options)\n",
    "# session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "# # from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "# # policy = mixed_precision.Policy('mixed_float16')\n",
    "# # mixed_precision.set_policy(policy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H4wdkGANBmj1"
   },
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Adding convolutional layers with activations on the same line for clarity\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),kernel_initializer=\"glorot_uniform\", padding='same', input_shape=(img_width, img_height, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), padding='same', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3, 3), padding='same', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(512, kernel_size=(3, 3), padding='same', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flattening and adding dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7HgpAMbFBtaF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w8pwFYgVJMjp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
